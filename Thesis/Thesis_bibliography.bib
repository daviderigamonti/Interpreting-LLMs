@inproceedings{bengio2020,
  author={Bengio, Yoshua and Ducharme, R\'{e}jean and Vincent, Pascal},
  booktitle={Advances in Neural Information Processing Systems},
  editor={T. Leen and T. Dietterich and V. Tresp},
  pages={},
  publisher={MIT Press},
  title={A Neural Probabilistic Language Model},
  url={https://proceedings.neurips.cc/paper_files/paper/2000/file/728f206c2a01bf572b5940d7d9a8fa4c-Paper.pdf},
  volume={13},
  year={2000}
}

@misc{mikolov2013,
  title={Efficient Estimation of Word Representations in Vector Space}, 
  author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
  year={2013},
  eprint={1301.3781},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/1301.3781}, 
}

@misc{vaswani2017,
  title={Attention Is All You Need}, 
  author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year={2017},
  eprint={1706.03762},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/1706.03762}, 
}

% -----------------

@misc{rai2024,
  title={A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models}, 
  author={Daking Rai and Yilun Zhou and Shi Feng and Abulhair Saparov and Ziyu Yao},
  year={2024},
  eprint={2407.02646},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2407.02646}, 
}

% TODO
@misc{olah2022,
  url={https://transformer-circuits.pub/2022/mech-interp-essay},
}

@misc{ferrando2024,
  title={A Primer on the Inner Workings of Transformer-based Language Models}, 
  author={Javier Ferrando and Gabriele Sarti and Arianna Bisazza and Marta R. Costa-juss√†},
  year={2024},
  eprint={2405.00208},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2405.00208}, 
}

@article{denil2014,
  author={Misha Denil and Alban Demiraj and Nando de Freitas},
  title={Extraction of Salient Sentences from Labelled Documents},
  journal={CoRR},
  volume={abs/1412.6815},
  year={2014}
}

@inproceedings{ding2021,
  title={Evaluating Saliency Methods for Neural Language Models},
  author={Ding, Shuoyang and Koehn, Philipp},
  editor={Toutanova, Kristina and Rumshisky, Anna and Zettlemoyer, Luke and Hakkani-Tur, Dilek and Beltagy, Iz and Bethard, Steven and Cotterell, Ryan and Chakraborty, Tanmoy and Zhou, Yichao},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month={jun},
  year={2021},
  address={Online},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2021.naacl-main.399},
  doi={10.18653/v1/2021.naacl-main.399},
  pages={5034--5052},
}

@inproceedings{sanyal2021,
  title={Discretized Integrated Gradients for Explaining Language Models},
  author={Sanyal, Soumya and Ren, Xiang},
  editor={Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  month={nov},
  year={2021},
  address={Online and Punta Cana, Dominican Republic},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2021.emnlp-main.805},
  doi={10.18653/v1/2021.emnlp-main.805},
  pages={10285--10299},
}

@inproceedings{enguehard2023,
  title={Sequential Integrated Gradients: a simple but effective method for explaining language models},
  author={Enguehard, Joseph},
  editor={Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  month={jul},
  year={2023},
  address={Toronto, Canada},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2023.findings-acl.477},
  doi={10.18653/v1/2023.findings-acl.477},
  pages={7555--7565},
}

@article{li2016,
  author={Jiwei Li and Will Monroe and Dan Jurafsky},
  title={Understanding Neural Networks through Representation Erasure},
  journal={CoRR},
  volume={abs/1612.08220},
  year={2016}
}

@article{amara2024,
  title={SyntaxShap: Syntax-aware Explainability Method for Text Generation},
  author={Kenza Amara and Rita Sevastjanova and Mennatallah El-Assady},
  journal={ArXiv},
  year={2024},
  volume={abs/2402.09259},
  url={https://api.semanticscholar.org/CorpusID:267657673}
}

@inproceedings{mohebbi2023,
  title={Quantifying Context Mixing in Transformers},
  author={Mohebbi, Hosein and Zuidema, Willem and Chrupa{\l}a, Grzegorz and Alishahi, Afra},
  editor={Vlachos, Andreas and Augenstein, Isabelle},
  booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  month={may},
  year={2023},
  address={Dubrovnik, Croatia},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2023.eacl-main.245},
  doi={10.18653/v1/2023.eacl-main.245},
  pages={3378--3400},
}

@article{sundararajan2017,
  author={Mukund Sundararajan and Ankur Taly and Qiqi Yan},
  title={Axiomatic Attribution for Deep Networks},
  journal={CoRR},
  volume={abs/1703.01365},
  year={2017}
}

@article{smilkov2017,
  author={Daniel Smilkov andNikhil Thorat andBeen Kim and Fernanda B. Vi{\'{e}}gas and Martin Wattenberg},
  title={SmoothGrad: removing noise by adding noise},
  journal={CoRR},
  volume={abs/1706.03825},
  year={2017}
}

@article{ribeiro2016,
  author={Marco T{\'{u}}lio Ribeiro and Sameer Singh and Carlos Guestrin},
  title={"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  journal={CoRR},
  volume={abs/1602.04938},
  year={2016}
}

@article{lundberg2017,
  author={Scott M. Lundberg and Su{-}In Lee},
  title={A unified approach to interpreting model predictions},
  journal={CoRR},
  volume={abs/1705.07874},
  year={2017}
}

@inproceedings{ferrando2022,
  title={Measuring the Mixing of Contextual Information in the Transformer},
  author={Ferrando, Javier and G{\'a}llego, Gerard I. and Costa-juss{\`a}, Marta R.},
  editor={Goldberg, Yoav and Kozareva, Zornitsa and Zhang, Yue},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  month={dec},
  year={2022},
  address={Abu Dhabi, United Arab Emirates},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2022.emnlp-main.595},
  doi={10.18653/v1/2022.emnlp-main.595},
  pages={8698--8714},
}

@inproceedings{modarressi2022,
  title={{G}lob{E}nc: Quantifying Global Token Attribution by Incorporating the Whole Encoder Layer in Transformers},
  author={Modarressi, Ali and Fayyaz, Mohsen and Yaghoobzadeh, Yadollah and Pilehvar, Mohammad Taher},
  editor={Carpuat, Marine and de Marneffe, Marie-Catherine and Meza Ruiz, Ivan Vladimir},
  booktitle={Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month={jul},
  year={2022},
  address={Seattle, United States},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2022.naacl-main.19},
  doi={10.18653/v1/2022.naacl-main.19},
  pages={258--271},
}

@inproceedings{yin2022,
  title={Interpreting Language Models with Contrastive Explanations},
  author={Yin, Kayo and Neubig, Graham},
  editor={Goldberg, Yoav and Kozareva, Zornitsa and Zhang, Yue},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  month={dec},
  year={2022},
  address={Abu Dhabi, United Arab Emirates},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2022.emnlp-main.14},
  doi={10.18653/v1/2022.emnlp-main.14},
  pages={184--198},
}

@misc{kwon2024,
  title={DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models}, 
  author={Yongchan Kwon and Eric Wu and Kevin Wu and James Zou},
  year={2024},
  eprint={2310.00902},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2310.00902},
}

@article{grosse2023,
  title={Studying Large Language Model Generalization with Influence Functions},
  author={Roger Baker Grosse and Juhan Bae and Cem Anil and Nelson Elhage and Alex Tamkin and Amirhossein Tajdini and Benoit Steiner and Dustin Li and Esin Durmus and Ethan Perez and Evan Hubinger and Kamil.e Lukovsiut.e and Karina Nguyen and Nicholas Joseph and Sam McCandlish and Jared Kaplan and Sam Bowman},
  journal={ArXiv},
  year={2023},
  volume={abs/2308.03296},
  url={https://api.semanticscholar.org/CorpusID:260682872}
}

@article{sixt2019,
  author={Leon Sixt and Maximilian Granz and Tim Landgraf},
  title={When Explanations Lie: Why Modified {BP} Attribution Fails},
  journal={CoRR},
  volume={abs/1912.09818},
  year={2019}
}

@article{adebayo2018,
  author={Julius Adebayo and Justin Gilmer and Michael Muelly and Ian J. Goodfellow and Moritz Hardt and Been Kim},
  title={Sanity Checks for Saliency Maps},
  journal={CoRR},
  volume={abs/1810.03292},
  year={2018}
}

@inproceedings{atanasova2020,
  title={A Diagnostic Study of Explainability Techniques for Text Classification},
  author={Atanasova, Pepa and Simonsen, Jakob Grue and Lioma, Christina and Augenstein, Isabelle},
  editor={Webber, Bonnie and Cohn, Trevor and He, Yulan and Liu, Yang},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  month={nov},
  year={2020},
  address={Online},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2020.emnlp-main.263},
  doi={10.18653/v1/2020.emnlp-main.263},
  pages={3256--3274},
}

@inproceedings{geva2022,
  title={Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space},
  author={Geva, Mor and Caciularu, Avi and Wang, Kevin and Goldberg, Yoav},
  editor={Goldberg, Yoav and Kozareva, Zornitsa and Zhang, Yue},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  month={dec},
  year={2022},
  address={Abu Dhabi, United Arab Emirates},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2022.emnlp-main.3},
  doi={10.18653/v1/2022.emnlp-main.3},
  pages={30--45},
}

@inproceedings{ferrando2023,
  title={Explaining How Transformers Use Context to Build Predictions},
  author={Ferrando, Javier and G{\'a}llego, Gerard I. and Tsiamas, Ioannis and Costa-juss{\`a}, Marta R.},
  editor={Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month={jul},
  year={2023},
  address={Toronto, Canada},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2023.acl-long.301},
  doi={10.18653/v1/2023.acl-long.301},
  pages={5486--5513},
}

@misc{wang2022,
  title={Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small}, 
  author={Kevin Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt},
  year={2022},
  eprint={2211.00593},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2211.00593}, 
}  

@article{geiger2021,
  author={Atticus Geiger and Hanson Lu and Thomas Icard and Christopher Potts},
  title={Causal Abstractions of Neural Networks},
  journal={CoRR},
  volume={abs/2106.02997},
  year={2021}
}

@article{olsson2022,
  title={In-context Learning and Induction Heads},
  author={Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Johnston, Scott and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
  year={2022},
  journal={Transformer Circuits Thread},
  url={https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html}
}

@inproceedings{meng2022,
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  booktitle={Advances in Neural Information Processing Systems},
  editor={S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages={17359--17372},
  publisher={Curran Associates, Inc.},
  title={Locating and Editing Factual Associations in GPT},
  url={https://proceedings.neurips.cc/paper_files/paper/2022/file/6f1d43d5a82a37e89b0665b33bf3a182-Paper-Conference.pdf},
  volume={35},
  year={2022}
}

@inproceedings{hanna2023,
  author={Hanna, Michael and Liu, Ollie and Variengien, Alexandre},
  booktitle={Advances in Neural Information Processing Systems},
  editor={A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
  pages={76033--76060},
  publisher={Curran Associates, Inc.},
  title={How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model},
  url={https://proceedings.neurips.cc/paper_files/paper/2023/file/efbba7719cc5172d175240f24be11280-Paper-Conference.pdf},
  volume={36},
  year={2023}
}

@inproceedings{conmy2023,
  author={Conmy, Arthur and Mavor-Parker, Augustine and Lynch, Aengus and Heimersheim, Stefan and Garriga-Alonso, Adri\`{a}},
  booktitle={Advances in Neural Information Processing Systems},
  editor={A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
  pages={16318--16352},
  publisher={Curran Associates, Inc.},
  title={Towards Automated Circuit Discovery for Mechanistic Interpretability},
  url={https://proceedings.neurips.cc/paper_files/paper/2023/file/34e1dbe95d34d7ebaf99b9bcaeb5b2be-Paper-Conference.pdf},
  volume={36},
  year={2023}
}

@misc{zhang2024,
  title={Towards Best Practices of Activation Patching in Language Models: Metrics and Methods}, 
  author={Fred Zhang and Neel Nanda},
  year={2024},
  eprint={2309.16042},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2309.16042}, 
}

@misc{lieberum2023,
  title={Does Circuit Analysis Interpretability Scale? Evidence from Multiple Choice Capabilities in Chinchilla}, 
  author={Tom Lieberum and Matthew Rahtz and J√°nos Kram√°r and Neel Nanda and Geoffrey Irving and Rohin Shah and Vladimir Mikulik},
  year={2023},
  eprint={2307.09458},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2307.09458}, 
}

@article{cammarata2020,
  author={Cammarata, Nick and Carter, Shan and Goh, Gabriel and Olah, Chris and Petrov, Michael and Schubert, Ludwig and Voss, Chelsea and Egan, Ben and Lim, Swee Kiat},
  title={Thread: Circuits},
  journal={Distill},
  year={2020},
  url={https://distill.pub/2020/circuits},
  doi={10.23915/distill.00024}
}
@InProceedings{kim2018,
  title={Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors ({TCAV})},
  author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and sayres, Rory},
  booktitle={Proceedings of the 35th International Conference on Machine Learning},
  pages={2668--2677},
  year={2018},
  editor={Dy, Jennifer and Krause, Andreas},
  volume={80},
  series={Proceedings of Machine Learning Research},
  month={10--15 Jul},
  publisher={PMLR},
  pdf={http://proceedings.mlr.press/v80/kim18d/kim18d.pdf},
  url={https://proceedings.mlr.press/v80/kim18d.html},
}

@article{belinkov2022,
  title={Probing Classifiers: Promises, Shortcomings, and Advances},
  author={Belinkov, Yonatan},
  journal={Computational Linguistics},
  volume={48},
  number={1},
  month={mar},
  year={2022},
  address={Cambridge, MA},
  publisher={MIT Press},
  url={https://aclanthology.org/2022.cl-1.7},
  doi={10.1162/coli_a_00422},
  pages={207--219},
}

@misc{chwang2024,
  title={Do Androids Know They're Only Dreaming of Electric Sheep?}, 
  author={Sky CH-Wang and Benjamin Van Durme and Jason Eisner and Chris Kedzie},
  year={2024},
  eprint={2312.17249},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2312.17249}, 
}

@misc{zou2023,
  title={Representation Engineering: A Top-Down Approach to AI Transparency}, 
  author={Andy Zou and Long Phan and Sarah Chen and James Campbell and Phillip Guo and Richard Ren and Alexander Pan and Xuwang Yin and Mantas Mazeika and Ann-Kathrin Dombrowski and Shashwat Goel and Nathaniel Li and Michael J. Byun and Zifan Wang and Alex Mallen and Steven Basart and Sanmi Koyejo and Dawn Song and Matt Fredrikson and J. Zico Kolter and Dan Hendrycks},
  year={2023},
  eprint={2310.01405},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2310.01405}, 
}

@online{macdiarmid2024,
  author={Monte MacDiarmid and Timothy Maxwell and Nicholas Schiefer and Jesse Mu and Jared Kaplan and David Duvenaud and Sam Bowman and Alex Tamkin and Ethan Perez and Mrinank Sharma and Carson Denison and Evan Hubinger},
  title={Simple probes can catch sleeper agents},
  date={2024-04-23},
  year={2024},
  url={https://www.anthropic.com/news/probes-catch-sleeper-agents},
}

@misc{burns2024,
  title={Discovering Latent Knowledge in Language Models Without Supervision}, 
  author={Collin Burns and Haotian Ye and Dan Klein and Jacob Steinhardt},
  year={2024},
  eprint={2212.03827},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2212.03827}, 
}

@article{devlin2018,
  author={Jacob Devlin and Ming{-}Wei Chang and Kenton Lee and Kristina Toutanova},
  title={{BERT:} Pre-training of Deep Bidirectional Transformers for Language Understanding},
  journal={CoRR},
  volume={abs/1810.04805},
  year={2018}
}

@article{tenney2019a,
  author={Ian Tenney and Patrick Xia and Berlin Chen and Alex Wang and Adam Poliak and R. Thomas McCoy and Najoung Kim and Benjamin Van Durme and Samuel R. Bowman and Dipanjan Das and Ellie Pavlick},
  title={What do you learn from context? Probing for sentence structure in contextualized word representations},
  journal={CoRR},
  volume={abs/1905.06316},
  year={2019}
}

@inproceedings{lin2019,
  title={Open Sesame: Getting inside {BERT}{'}s Linguistic Knowledge},
  author={Lin, Yongjie and Tan, Yi Chern and Frank, Robert},
  editor={Linzen, Tal and Chrupa{\l}a, Grzegorz and Belinkov, Yonatan and Hupkes, Dieuwke},
  booktitle={Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  month={aug},
  year={2019},
  address={Florence, Italy},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/W19-4825},
  doi={10.18653/v1/W19-4825},
  pages={241--253},
}

@inproceedings{liu2019,
  title={Linguistic Knowledge and Transferability of Contextual Representations},
  author={Liu, Nelson F. and Gardner, Matt and Belinkov, Yonatan and Peters, Matthew E. and Smith, Noah A.},
  editor={Burstein, Jill and Doran, Christy and Solorio, Thamar},
  booktitle={Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  month={jun},
  year={2019},
  address={Minneapolis, Minnesota},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/N19-1112},
  doi={10.18653/v1/N19-1112},
  pages={1073--1094},
}

@inproceedings{hewitt2019,
  title={{A} Structural Probe for Finding Syntax in Word Representations},
  author={Hewitt, John and Manning, Christopher D.},
  editor={Burstein, Jill and Doran, Christy and Solorio, Thamar},
  booktitle={Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  month={jun},
  year={2019},
  address={Minneapolis, Minnesota},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/N19-1419},
  doi={10.18653/v1/N19-1419},
  pages={4129--4138},
}

@inproceedings{tenney2019b,
  title={{BERT} Rediscovers the Classical {NLP} Pipeline},
  author={Tenney, Ian and Das, Dipanjan and Pavlick, Ellie},
  editor={Korhonen, Anna and Traum, David and M{\`a}rquez, Llu{\'\i}s},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  month={jul},
  year={2019},
  address={Florence, Italy},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/P19-1452},
  doi={10.18653/v1/P19-1452},
  pages={4593--4601},
}

@misc{park2023,
  title={The Linear Representation Hypothesis and the Geometry of Large Language Models}, 
  author={Kiho Park and Yo Joong Choe and Victor Veitch},
  year={2023},
  eprint={2311.03658},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2311.03658}, 
}

@misc{voita2023,
  title={Neurons in Large Language Models: Dead, N-gram, Positional}, 
  author={Elena Voita and Javier Ferrando and Christoforos Nalmpantis},
  year={2023},
  eprint={2309.04827},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2309.04827}, 
}

@misc{jiang2024,
  title={On the Origins of Linear Representations in Large Language Models}, 
  author={Yibo Jiang and Goutham Rajendran and Pradeep Ravikumar and Bryon Aragam and Victor Veitch},
  year={2024},
  eprint={2403.03867},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2403.03867}, 
}
  
@inproceedings{ravfogel2020,
  title={Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection},
  author={Ravfogel, Shauli and Elazar, Yanai and Gonen, Hila and Twiton, Michael and Goldberg, Yoav},
  editor={Jurafsky, Dan and Chai, Joyce and Schluter, Natalie and Tetreault, Joel},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  month={jul},
  year={2020},
  address={Online},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2020.acl-main.647},
  doi={10.18653/v1/2020.acl-main.647},
  pages={7237--7256},
}

@article{ravfogel2022,
  author={Shauli Ravfogel and Michael Twiton and Yoav Goldberg and Ryan Cotterell},
  title={Linear Adversarial Concept Erasure},
  journal={CoRR},
  volume={abs/2201.12091},
  year={2022}
}

@misc{belrose2023b,
  title={LEACE: Perfect linear concept erasure in closed form}, 
  author={Nora Belrose and David Schneider-Joseph and Shauli Ravfogel and Ryan Cotterell and Edward Raff and Stella Biderman},
  year={2023},
  eprint={2306.03819},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2306.03819}, 
}
 
@inproceedings{nanda2023,
  title={Emergent Linear Representations in World Models of Self-Supervised Sequence Models},
  author={Nanda, Neel and Lee, Andrew and Wattenberg, Martin},
  editor={Belinkov, Yonatan and Hao, Sophie and Jumelet, Jaap and Kim, Najoung and McCarthy, Arya and Mohebbi, Hosein},
  booktitle={Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP},
  month={dec},
  year={2023},
  address={Singapore},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2023.blackboxnlp-1.2},
  doi={10.18653/v1/2023.blackboxnlp-1.2},
  pages={16--30},
}

@misc{turner2024,
  title={Activation Addition: Steering Language Models Without Optimization}, 
  author={Alexander Matt Turner and Lisa Thiergart and Gavin Leech and David Udell and Juan J. Vazquez and Ulisse Mini and Monte MacDiarmid},
  year={2024},
  eprint={2308.10248},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2308.10248}, 
}

% TODO
@misc{olah2023,
  url={https://transformer-circuits.pub/2023/superposition-composition/index.html},
}

@article{elhage2022,
  title={Toy Models of Superposition},
  author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and Grosse, Roger and McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Wattenberg, Martin and Olah, Christopher},
  year={2022},
  journal={Transformer Circuits Thread},
  url={https://transformer-circuits.pub/2022/toy_model/index.html},
}

@article{arora2018,
  title={Linear Algebraic Structure of Word Senses, with Applications to Polysemy},
  author={Arora, Sanjeev and Li, Yuanzhi and Liang, Yingyu and Ma, Tengyu and Risteski, Andrej},
  editor={Lee, Lillian and Johnson, Mark and Toutanova, Kristina and Roark, Brian},
  journal={Transactions of the Association for Computational Linguistics},
  volume={6},
  year={2018},
  address={Cambridge, MA},
  publisher={MIT Press},
  url={https://aclanthology.org/Q18-1034},
  doi={10.1162/tacl_a_00034},
  pages={483--495},
}

@misc{gurnee2023,
  title={Finding Neurons in a Haystack: Case Studies with Sparse Probing}, 
  author={Wes Gurnee and Neel Nanda and Matthew Pauly and Katherine Harvey and Dmitrii Troitskii and Dimitris Bertsimas},
  year={2023},
  eprint={2305.01610},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2305.01610}, 
}

@article{bricken2023,
  title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
  author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
  year={2023},
  journal={Transformer Circuits Thread},
  url={https://transformer-circuits.pub/2023/monosemantic-features/index.html}
}

@misc{cunningham2023,
  title={Sparse Autoencoders Find Highly Interpretable Features in Language Models}, 
  author={Hoagy Cunningham and Aidan Ewart and Logan Riggs and Robert Huben and Lee Sharkey},
  year={2023},
  eprint={2309.08600},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2309.08600}, 
}

% TODO
@misc{nostalgebraist2020,
  url={https://www.alignmentforum.org/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens},
}

@article{jastrzebski2017,
  author={Stanislaw Jastrzebski and Devansh Arpit and Nicolas Ballas and Vikas Verma and Tong Che and Yoshua Bengio},
  title={Residual Connections Encourage Iterative Inference},
  journal={CoRR},
  volume={abs/1710.04773},
  year={2017}
}

@misc{din2024,
  title={Jump to Conclusions: Short-Cutting Transformers With Linear Transformations}, 
  author={Alexander Yom Din and Taelin Karidi and Leshem Choshen and Mor Geva},
  year={2024},
  eprint={2303.09435},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2303.09435}, 
}

@misc{belrose2023a,
  title={Eliciting Latent Predictions from Transformers with the Tuned Lens}, 
  author={Nora Belrose and Zach Furman and Logan Smith and Danny Halawi and Igor Ostrovsky and Lev McKinney and Stella Biderman and Jacob Steinhardt},
  year={2023},
  eprint={2303.08112},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2303.08112}, 
}

@misc{sakarvadia2023,
  title={Attention Lens: A Tool for Mechanistically Interpreting the Attention Head Information Retrieval Mechanism}, 
  author={Mansi Sakarvadia and Arham Khan and Aswathy Ajith and Daniel Grzenda and Nathaniel Hudson and Andr√© Bauer and Kyle Chard and Ian Foster},
  year={2023},
  eprint={2310.16270},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2310.16270}, 
}

@inproceedings{pal2023,
  title={Future Lens: Anticipating Subsequent Tokens from a Single Hidden State},
  author={Pal, Koyena and Sun, Jiuding and Yuan, Andrew and Wallace, Byron and Bau, David},
  editor={Jiang, Jing and Reitter, David and Deng, Shumin},
  booktitle={Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL)},
  month={dec},
  year={2023},
  address={Singapore},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2023.conll-1.37},
  doi={10.18653/v1/2023.conll-1.37},
  pages={548--560},
}

@misc{ghandeharioun2024,
  title={Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models}, 
  author={Asma Ghandeharioun and Avi Caciularu and Adam Pearce and Lucas Dixon and Mor Geva},
  year={2024},
  eprint={2401.06102},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2401.06102}, 
}

@inproceedings{dar2023,
  title={Analyzing Transformers in Embedding Space},
  author={Dar, Guy and Geva, Mor and Gupta, Ankit and Berant, Jonathan},
  editor={Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month={jul},
  year={2023},
  address={Toronto, Canada},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2023.acl-long.893},
  doi={10.18653/v1/2023.acl-long.893},
  pages={16124--16170},
}

% TODO
@misc{millidge2022,
  url={https://www.alignmentforum.org/posts/mkbGjzxD8d8XqKHzA/the-singular-value-decompositions-of-transformer-weight},
}

@misc{cancedda2024,
  title={Spectral Filters, Dark Signals, and Attention Sinks}, 
  author={Nicola Cancedda},
  year={2024},
  eprint={2402.09221},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2402.09221}, 
}

@article{dalvi2018,
  author={Fahim Dalvi and Nadir Durrani and Hassan Sajjad and Yonatan Belinkov and Anthony Bau and James R. Glass},
  title={What Is One Grain of Sand in the Desert? Analyzing Individual Neurons in Deep {NLP} Models},
  journal={CoRR},
  volume={abs/1812.09355},
  year={2018}
}

@misc{bills2023,
  title={Language models can explain neurons in language models},
  author={Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William},
  year={2023},
  howpublished={\url{https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html}}
}

@article{bolukbasi2021,
  author={Tolga Bolukbasi and Adam Pearce and Ann Yuan and Andy Coenen and Emily Reif and Fernanda B. Vi{\'{e}}gas and Martin Wattenberg},
  title={An Interpretability Illusion for {BERT}},
  journal={CoRR},
  volume={abs/2104.07143},
  year={2021}
}

@inproceedings{huang2023,
  title={Rigorously Assessing Natural Language Explanations of Neurons},
  author={Huang, Jing and Geiger, Atticus and D{'}Oosterlinck, Karel and Wu, Zhengxuan and Potts, Christopher},
  editor={Belinkov, Yonatan and Hao, Sophie and Jumelet, Jaap and Kim, Najoung and McCarthy, Arya and Mohebbi, Hosein},
  booktitle={Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP},
  month={dec},
  year={2023},
  address={Singapore},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2023.blackboxnlp-1.24},
  doi={10.18653/v1/2023.blackboxnlp-1.24},
  pages={317--331},
}
