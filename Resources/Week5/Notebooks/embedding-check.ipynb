{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install einops","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-13T11:05:44.097169Z","iopub.execute_input":"2023-12-13T11:05:44.097974Z","iopub.status.idle":"2023-12-13T11:05:56.671597Z","shell.execute_reply.started":"2023-12-13T11:05:44.097940Z","shell.execute_reply":"2023-12-13T11:05:56.670495Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting einops\n  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\nDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport torch\nimport copy\n\nimport pandas as pd\n\nfrom tqdm.notebook import tqdm\n\nfrom gensim.test.utils import datapath\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:05:56.673635Z","iopub.execute_input":"2023-12-13T11:05:56.673932Z","iopub.status.idle":"2023-12-13T11:06:12.531641Z","shell.execute_reply.started":"2023-12-13T11:05:56.673904Z","shell.execute_reply":"2023-12-13T11:06:12.530668Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import Models","metadata":{}},{"cell_type":"code","source":"device = \"cuda\"\ntorch.set_default_device(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:12.532814Z","iopub.execute_input":"2023-12-13T11:06:12.533265Z","iopub.status.idle":"2023-12-13T11:06:12.538808Z","shell.execute_reply.started":"2023-12-13T11:06:12.533239Z","shell.execute_reply":"2023-12-13T11:06:12.537661Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"phi = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\ntokenizer_phi = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\nconfig_phi = AutoConfig.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\n\nphi = phi.eval()\nphi.zero_grad()","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:12.541674Z","iopub.execute_input":"2023-12-13T11:06:12.541933Z","iopub.status.idle":"2023-12-13T11:06:34.532074Z","shell.execute_reply.started":"2023-12-13T11:06:12.541910Z","shell.execute_reply":"2023-12-13T11:06:34.531284Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cdcbc1584ae4709a895d5cf9072fdbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi.py:   0%|          | 0.00/2.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f6f7142de6845e887dcba2f3f6ea56a"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-1_5:\n- configuration_phi.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi.py:   0%|          | 0.00/33.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34e86a8dddd3406ba638051a68d6021f"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-1_5:\n- modeling_phi.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.84G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa532ffb1c7345e081468f931d0bb046"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32fb465f24164d1292ca8b883f15f61d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e08d705201184ecbbdddd063a4583666"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0073aadfc41046ed98fa25e9e1853cd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2eab0d289b034727af797c32179ef8df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fa2050da4af4894bb3bf26d9e271273"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cc28e1155b84c919d9455cc78571fbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b18721bd5f6484c9592a1ad5e03c86d"}},"metadata":{}}]},{"cell_type":"code","source":"gpt = AutoModelForCausalLM.from_pretrained(\"gpt2\")\ntokenizer_gpt = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\nconfig_gpt = AutoConfig.from_pretrained(\"gpt2\", trust_remote_code=True)\n\ngpt.eval()\ngpt.zero_grad()","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:34.533098Z","iopub.execute_input":"2023-12-13T11:06:34.533359Z","iopub.status.idle":"2023-12-13T11:06:39.094298Z","shell.execute_reply.started":"2023-12-13T11:06:34.533336Z","shell.execute_reply":"2023-12-13T11:06:39.093533Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cf5842664bd42e08056d4be90b698a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a059670b87ef486c8da36c45544c180d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d91217c7652e43e29f6263c46dee1785"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97329070e35a4472868f1f0b3f020846"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07d01bbd78704d6ea94dea16c3bbd6ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e7ee6433d36445eac1c48a82b878bca"}},"metadata":{}}]},{"cell_type":"code","source":"phi_emb = phi.get_input_embeddings()\ngpt_emb = gpt.get_input_embeddings()","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:39.095396Z","iopub.execute_input":"2023-12-13T11:06:39.095681Z","iopub.status.idle":"2023-12-13T11:06:39.100132Z","shell.execute_reply.started":"2023-12-13T11:06:39.095656Z","shell.execute_reply":"2023-12-13T11:06:39.099070Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Define Helper Functions","metadata":{}},{"cell_type":"code","source":"def multiencode(tok, words, return_tensors=\"pt\"):\n    if (isinstance(words, list) or isinstance(words, tuple)) and not isinstance(words, str):\n        return torch.cat([tok.encode(word, return_tensors=\"pt\") for word in words], dim=-1)\n    else:\n        return tok.encode(words, return_tensors=\"pt\")\n    \ndef avgencode(emb, word, tok=None, avg=True):\n    source = word\n    # If input is a string tokenize it\n    if (isinstance(word, str) or isinstance(word[0], str)) and tok is not None:\n        word = emb(multiencode(tok, word))\n    # Calculate average if avg flag is true and if it is needed\n    if word.shape[1] != 1 and avg:\n        word = torch.unsqueeze(torch.mean(word, dim=1), dim=1)\n    elif word.shape[1] != 1 and not avg:\n        raise Exception(f\"{source} is not a single token: {word}\")\n    return word","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:39.101288Z","iopub.execute_input":"2023-12-13T11:06:39.101590Z","iopub.status.idle":"2023-12-13T11:06:39.112113Z","shell.execute_reply.started":"2023-12-13T11:06:39.101562Z","shell.execute_reply":"2023-12-13T11:06:39.111195Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def calc_distance(emb, word1, word2, tok=None, avg=True, dist=\"cosine\", multi=False):\n    # Encode and average (if multi is True, word1 represents the embedding matrix)\n    if not multi:\n        word1 = avgencode(emb, word1, tok, avg=avg)\n    word2 = avgencode(emb, word2, tok, avg=avg)\n    # Compute distances\n    if dist == \"L2\":\n        distances = torch.norm(word1 - word2, dim=2)\n    elif dist == \"cosine\":\n        cs = torch.nn.CosineSimilarity(dim=2)\n        distances = 1 - cs(word1, word2)\n    else:\n        raise Exception(\"Unknown distance\")\n    return distances\n\ndef get_closest_emb(emb, word, k=1, decode=True, tok=None, avg=True, dist=\"cosine\"):\n    # Compute distances\n    distances = calc_distance(emb, emb.weight.data, word, tok=tok, avg=avg, dist=dist, multi=True)\n    # Compute top k smalles indices\n    topk = torch.squeeze(torch.topk(distances, k=k, largest=False).indices)\n    # If one element, unsqueeze it\n    if k == 1:\n        topk = torch.unsqueeze(topk, dim=0)\n    # Decode closest k\n    if decode and tok is not None:\n        topk = [tok.decode(c) for c in topk.tolist()]\n    return topk\n\ndef emb_arithmetic(emb, tok, words, k=1, avg=True, dist=\"cosine\"):\n    # Encode and average\n    words_emb = [avgencode(emb, word, tok, avg=avg) for word in words]\n    # Compute embeddings\n    w1 = words_emb[0]\n    w2 = words_emb[1]\n    w3 = words_emb[2]\n    # Do embedding arithmetic\n    if dist == \"L2\":\n        w = torch.nn.functional.normalize(w1 - w2 + w3, dim=0)\n    else:\n        w = w1 - w2 + w3\n    # Get closest k\n    closest = get_closest_emb(emb, w, k=k, decode=True, tok=tok, dist=dist)\n    return (w, closest)\n\ndef print_results(res):\n     for i, r in enumerate(res):\n        print(f\"{i+1}) {r}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:39.113579Z","iopub.execute_input":"2023-12-13T11:06:39.113943Z","iopub.status.idle":"2023-12-13T11:06:39.127476Z","shell.execute_reply.started":"2023-12-13T11:06:39.113912Z","shell.execute_reply":"2023-12-13T11:06:39.126679Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def batch_emb_arithmetic(emb, tok, queries, k=5, avg=True, dist=\"cosine\", out=True):\n    ret = []\n    for q in queries:\n        if out:\n            print(\"##########################\")\n            # Print title\n            title_q = q\n            if not isinstance(q[0], str):\n                title_q = [qq[0] for qq in q]\n            print(f\"{title_q[0]} - {title_q[1]} + {title_q[2]} =\")\n        # Compute and print results\n        res = emb_arithmetic(emb, tok, q, k=k, avg=avg, dist=dist)\n        if out:\n            print_results(res[1])\n        ret.append(res)\n    return ret\n\ndef evaluate_batch(results, solutions, out=True):\n    \n    def get_rank(r, s, out=0):\n        try:\n            return r.index(s)\n        except ValueError:\n            return out\n    \n    k = len(results[0][1])\n    ev = []\n    for res, sol in zip(list(map(lambda x: x[1], results)), solutions):\n        # Get rank of each solution for each result outputs\n        ranks = [get_rank(res, s, out=k) for s in sol]\n        # Append best rank to final evaluation list\n        ev.append(min(ranks))\n    # Return score\n    score = 1 - ( sum(ev) / (k * len(solutions)) )\n    if out:\n        print(f\"{ev} -> {score}\")\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:39.128661Z","iopub.execute_input":"2023-12-13T11:06:39.129013Z","iopub.status.idle":"2023-12-13T11:06:39.145610Z","shell.execute_reply.started":"2023-12-13T11:06:39.128985Z","shell.execute_reply":"2023-12-13T11:06:39.144746Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Define Test Cases","metadata":{}},{"cell_type":"markdown","source":"### Capital Arithmetic","metadata":{}},{"cell_type":"code","source":"capital_arithmetic = [\n    [\"Rome Rome\", \"Italy Italy\", \"France France\"],\n    [\"Rome Rome\", \"Italy Italy\", \"Australia Australia\"],\n    [\"Paris Paris\", \"France France\", \"Italy Italy\"],\n    [\"Paris Paris\", \"France France\", \"Australia Australia\"],\n    [\"Canberra Canberra\", \"Australia Australia\", \"Italy Italy\"],\n    [\"Canberra Canberra\", \"Australia Australia\", \"France France\"],\n]\ncapital_single = [\n    [\" Rome\", \" Italy\", \" France\"],\n    [\" Rome\", \" Italy\", \" Australia\"],\n    [\" Paris\", \" France\", \" Italy\"],\n    [\" Paris\", \" France\", \" Australia\"],\n    [\" Canberra\", \" Australia\", \" Italy\"],\n    [\" Canberra\", \" Australia\", \" France\"],\n]\ncapital_arithmetic_lowercase = [\n    [\"rome rome\", \"italy italy\", \"france france\"],\n    [\"rome rome\", \"italy italy\", \"australia australia\"],\n    [\"paris paris\", \"france france\", \"italy italy\"],\n    [\"paris paris\", \"france france\", \"australia australia\"],\n    [\"canberra canberra\", \"australia australia\", \"italy italy\"],\n    [\"canberra canberra\", \"australia australia\", \"france france\"],\n]\ncapital_sol = [\n    [\"Paris\", \" Paris\", \"paris\", \" paris\"],\n    [\"Canberra\", \" Canberra\", \"canberra\", \" canberra\"],\n    [\"Rome\", \" Rome\", \"rome\", \" rome\"],\n    [\"Canberra\", \" Canberra\", \"canberra\", \" canberra\"],\n    [\"Rome\", \" Rome\", \"rome\", \" rome\"],\n    [\"Paris\", \" Paris\", \"paris\", \" paris\"],\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:39.150064Z","iopub.execute_input":"2023-12-13T11:06:39.150885Z","iopub.status.idle":"2023-12-13T11:06:39.160694Z","shell.execute_reply.started":"2023-12-13T11:06:39.150851Z","shell.execute_reply":"2023-12-13T11:06:39.159927Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Sex Arithmetic","metadata":{}},{"cell_type":"code","source":"sex_arithmetic = [\n    [\"King King\", \"Man Man\", \"Woman Woman\"],\n    [\"Queen Queen\", \"Woman Woman\", \"Man Man\"],\n    [\"Prince Prince\", \"Man Man\", \"Woman Woman\"],\n    [\"Princess Princess\", \"Woman Woman\", \"Man Man\"],\n    [\"Priest Priest\", \"Man Man\", \"Woman Woman\"],\n    [\"Nun Nun\", \"Woman Woman\", \"Man Man\"],\n]\nsex_arithmetic_lowercase_single = [\n    [\" king\", \" man\", \" woman\"],\n    [\" queen\", \" woman\", \" man\"],\n    [\" prince\", \" man\", \" woman\"],\n    [\" princess\", \" woman\", \" man\"],\n    [\" priest\", \" man\", \" woman\"],\n    [\" nun\", \" woman\", \" man\"],\n]\nsex_sol = [\n    [\"Queen\", \" Queen\", \"queen\", \" queen\"],\n    [\"King\", \" King\", \"king\", \" king\"],\n    [\"Princess\", \" Princess\", \"princess\", \" princess\"],\n    [\"Prince\", \" Prince\", \"prince\", \" prince\"],\n    [\"Nun\", \" Nun\", \"nun\", \" nun\"],\n    [\"Priest\", \" Priest\", \"priest\", \" priest\"],\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:39.161793Z","iopub.execute_input":"2023-12-13T11:06:39.162425Z","iopub.status.idle":"2023-12-13T11:06:39.175116Z","shell.execute_reply.started":"2023-12-13T11:06:39.162399Z","shell.execute_reply":"2023-12-13T11:06:39.174356Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Calculate and Display Test Results","metadata":{}},{"cell_type":"code","source":"test_capital = [\n    [\"Phi-1.5\", batch_emb_arithmetic(phi_emb, tokenizer_phi, capital_arithmetic, k=100, out=False)],\n    [\"Phi-1.5 Lowercase\", batch_emb_arithmetic(phi_emb, tokenizer_phi, capital_arithmetic_lowercase, k=100, out=False)],\n    [\"Phi-1.5 Single\", batch_emb_arithmetic(phi_emb, tokenizer_phi, capital_single, k=100, out=False)],\n    [\"GPT-2\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, capital_arithmetic, k=100, out=False)],\n    [\"GPT-2 Lowercase\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, capital_arithmetic_lowercase, k=100, out=False)],\n    [\"GPT-2 Single\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, capital_single, k=100, out=False)],\n]\ntest_sex = [\n    [\"Phi-1.5\", batch_emb_arithmetic(phi_emb, tokenizer_phi, sex_arithmetic, k=100, out=False)],\n    [\"Phi-1.5 Lowercase Single\", batch_emb_arithmetic(phi_emb, tokenizer_phi, sex_arithmetic_lowercase_single, k=100, out=False)],\n    [\"GPT-2\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, sex_arithmetic, k=100, out=False)],\n    [\"GPT-2 Lowercase Single\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, sex_arithmetic_lowercase_single, k=100, out=False)],\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:39.176175Z","iopub.execute_input":"2023-12-13T11:06:39.176456Z","iopub.status.idle":"2023-12-13T11:06:50.626941Z","shell.execute_reply.started":"2023-12-13T11:06:39.176432Z","shell.execute_reply":"2023-12-13T11:06:50.626169Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(\"Capital rankings\")\nfor name, result in test_capital:\n    print(\"---------------------------\")\n    print(name)\n    evaluate_batch(result, capital_sol)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:50.628041Z","iopub.execute_input":"2023-12-13T11:06:50.628329Z","iopub.status.idle":"2023-12-13T11:06:50.633991Z","shell.execute_reply.started":"2023-12-13T11:06:50.628303Z","shell.execute_reply":"2023-12-13T11:06:50.633124Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Capital rankings\n---------------------------\nPhi-1.5\n[13, 34, 8, 17, 14, 6] -> 0.8466666666666667\n---------------------------\nPhi-1.5 Lowercase\n[100, 100, 100, 100, 100, 100] -> 0.0\n---------------------------\nPhi-1.5 Single\n[4, 27, 12, 23, 16, 5] -> 0.855\n---------------------------\nGPT-2\n[2, 6, 7, 7, 10, 4] -> 0.94\n---------------------------\nGPT-2 Lowercase\n[100, 100, 100, 100, 100, 100] -> 0.0\n---------------------------\nGPT-2 Single\n[2, 4, 6, 8, 8, 3] -> 0.9483333333333334\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Sex rankings\")\nfor name, result in test_sex:\n    print(\"---------------------------\")\n    print(name)\n    evaluate_batch(result, sex_sol)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:50.635323Z","iopub.execute_input":"2023-12-13T11:06:50.635671Z","iopub.status.idle":"2023-12-13T11:06:50.651223Z","shell.execute_reply.started":"2023-12-13T11:06:50.635638Z","shell.execute_reply":"2023-12-13T11:06:50.650428Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Sex rankings\n---------------------------\nPhi-1.5\n[7, 7, 5, 13, 100, 100] -> 0.6133333333333333\n---------------------------\nPhi-1.5 Lowercase Single\n[4, 5, 2, 3, 19, 11] -> 0.9266666666666666\n---------------------------\nGPT-2\n[4, 2, 3, 5, 100, 100] -> 0.6433333333333333\n---------------------------\nGPT-2 Lowercase Single\n[1, 1, 1, 1, 6, 5] -> 0.975\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Visualizations ","metadata":{}},{"cell_type":"code","source":"_ = batch_emb_arithmetic(gpt_emb, tokenizer_gpt, capital_arithmetic, k=10)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:50.652599Z","iopub.execute_input":"2023-12-13T11:06:50.652915Z","iopub.status.idle":"2023-12-13T11:06:50.695836Z","shell.execute_reply.started":"2023-12-13T11:06:50.652884Z","shell.execute_reply":"2023-12-13T11:06:50.695084Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"##########################\nRome Rome - Italy Italy + France France =\n1) France\n2)  France\n3)  Paris\n4) ome\n5) French\n6)  French\n7) Paris\n8) R\n9)  Rou\n10)  Hollande\n##########################\nRome Rome - Italy Italy + Australia Australia =\n1)  Australia\n2) Australia\n3)  Australian\n4)  Sydney\n5) Australian\n6)  Australians\n7)  Canberra\n8)  Melbourne\n9)  Aboriginal\n10)  Perth\n##########################\nParis Paris - France France + Italy Italy =\n1) Paris\n2) Italy\n3)  Italy\n4)  Paris\n5)  Milan\n6) Italian\n7)  Italian\n8)  Rome\n9)  Italians\n10)  Venice\n##########################\nParis Paris - France France + Australia Australia =\n1) Australia\n2)  Australia\n3)  Sydney\n4)  Australian\n5)  Melbourne\n6) Paris\n7) Australian\n8)  Canberra\n9)  Paris\n10)  Australians\n##########################\nCanberra Canberra - Australia Australia + Italy Italy =\n1) Italy\n2)  Italy\n3) Italian\n4)  Italians\n5)  Italian\n6)  Sicily\n7) berra\n8)  Juventus\n9)  Naples\n10)  Milan\n##########################\nCanberra Canberra - Australia Australia + France France =\n1) France\n2)  France\n3) French\n4)  French\n5) Paris\n6)  Hollande\n7) berra\n8)  François\n9)  Paris\n10)  Francois\n","output_type":"stream"}]},{"cell_type":"code","source":"_ = batch_emb_arithmetic(phi_emb, tokenizer_phi, capital_arithmetic, k=10)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:50.696898Z","iopub.execute_input":"2023-12-13T11:06:50.697171Z","iopub.status.idle":"2023-12-13T11:06:50.774483Z","shell.execute_reply.started":"2023-12-13T11:06:50.697146Z","shell.execute_reply":"2023-12-13T11:06:50.773677Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"##########################\nRome Rome - Italy Italy + France France =\n1)  France\n2) France\n3) ome\n4) R\n5)  Rome\n6)  R\n7)  French\n8) r\n9) M\n10) E\n##########################\nRome Rome - Italy Italy + Australia Australia =\n1)  Australia\n2) Australia\n3) R\n4)  Australian\n5) ome\n6)  Australians\n7) Australian\n8)  R\n9)  Rome\n10) r\n##########################\nParis Paris - France France + Italy Italy =\n1)  Paris\n2) Paris\n3)  Italy\n4) Italy\n5)  Italian\n6) Italian\n7)  Milan\n8)  Italians\n9)  Rome\n10)  Lisbon\n##########################\nParis Paris - France France + Australia Australia =\n1)  Australia\n2) Australia\n3)  Paris\n4) Paris\n5)  Australian\n6) Australian\n7)  Australians\n8)  Sydney\n9)  Melbourne\n10)  Queensland\n##########################\nCanberra Canberra - Australia Australia + Italy Italy =\n1)  Italy\n2) Italy\n3) Can\n4)  Italian\n5) Italian\n6)  Italians\n7)  Canberra\n8) berra\n9) Could\n10)  Can\n##########################\nCanberra Canberra - Australia Australia + France France =\n1)  France\n2) France\n3) Can\n4)  French\n5) French\n6)  Canberra\n7) Paris\n8)  Paris\n9) berra\n10)  french\n","output_type":"stream"}]},{"cell_type":"code","source":"_ = batch_emb_arithmetic(gpt_emb, tokenizer_gpt, sex_arithmetic_lowercase_single, k=10)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:50.775536Z","iopub.execute_input":"2023-12-13T11:06:50.775774Z","iopub.status.idle":"2023-12-13T11:06:50.813069Z","shell.execute_reply.started":"2023-12-13T11:06:50.775752Z","shell.execute_reply":"2023-12-13T11:06:50.812148Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"##########################\n king -  man +  woman =\n1)  king\n2)  queen\n3)  princess\n4)  Queen\n5)  kings\n6) Queen\n7)  King\n8)  woman\n9)  monarch\n10)  queens\n##########################\n queen -  woman +  man =\n1)  queen\n2)  king\n3)  queens\n4)  Queen\n5)  kings\n6)  King\n7)  man\n8)  emperor\n9)  prince\n10) Queen\n##########################\n prince -  man +  woman =\n1)  prince\n2)  princess\n3)  princes\n4)  Princess\n5) Prince\n6)  Prince\n7) Prin\n8)  girl\n9)  woman\n10)  queen\n##########################\n princess -  woman +  man =\n1)  princess\n2)  prince\n3)  princes\n4)  king\n5)  Princess\n6)  Prince\n7)  man\n8)  kings\n9) Prince\n10)  royal\n##########################\n priest -  man +  woman =\n1)  priest\n2)  priests\n3)  woman\n4)  Priest\n5)  nuns\n6)  clergy\n7)  nun\n8)  prostitute\n9)  bishop\n10)  priesthood\n##########################\n nun -  woman +  man =\n1)  nun\n2)  monk\n3)  man\n4)  nuns\n5)  convent\n6)  priest\n7)  monks\n8)  monastery\n9)  Jesuit\n10)  pope\n","output_type":"stream"}]},{"cell_type":"code","source":"res = get_closest_emb(phi_emb, \" nun\", k=10, tok=tokenizer_phi)\nprint_results(res)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:50.814151Z","iopub.execute_input":"2023-12-13T11:06:50.814481Z","iopub.status.idle":"2023-12-13T11:06:50.831163Z","shell.execute_reply.started":"2023-12-13T11:06:50.814447Z","shell.execute_reply":"2023-12-13T11:06:50.830229Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"1)  nun\n2)  nuns\n3)  Nun\n4)  convent\n5)  monk\n6)  monks\n7)  Sister\n8)  monastery\n9)  preacher\n10)  Sisters\n","output_type":"stream"}]},{"cell_type":"code","source":"res = get_closest_emb(gpt_emb, \" nun\", k=10, tok=tokenizer_gpt)\nprint_results(res)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:50.832077Z","iopub.execute_input":"2023-12-13T11:06:50.832332Z","iopub.status.idle":"2023-12-13T11:06:50.842070Z","shell.execute_reply.started":"2023-12-13T11:06:50.832309Z","shell.execute_reply":"2023-12-13T11:06:50.841213Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"1)  nun\n2)  nuns\n3)  convent\n4)  monk\n5)  monastery\n6)  priest\n7)  Sister\n8)  monks\n9)  Nun\n10)  Jesuit\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Gensim datasets","metadata":{}},{"cell_type":"code","source":"addspace = lambda x: \" \" + x\naddall = lambda x: (x.capitalize(), \" \" + x.capitalize(), x.lower(), \" \" + x.lower())","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:50.843005Z","iopub.execute_input":"2023-12-13T11:06:50.843237Z","iopub.status.idle":"2023-12-13T11:06:50.848309Z","shell.execute_reply.started":"2023-12-13T11:06:50.843215Z","shell.execute_reply":"2023-12-13T11:06:50.847292Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def load_question_words(path):\n    with open(path, 'r') as file:\n        lines = file.readlines()\n    data = {}\n    current_category = None\n    for line in lines:\n        line = line.strip()\n        # Check if the line denotes a new category\n        if line.startswith(':'):\n            current_category = line[2:]\n            data[current_category] = []\n        else:\n            data[current_category].append(line.split())\n    # Create DataFrames for each category\n    dfs = {}\n    for category, attributes in data.items():\n        df = pd.DataFrame(attributes, columns=['A', 'B', 'Solution', 'C'])\n        # Reassign order\n        df = df.reindex(columns = ['A', 'B', 'C', 'Solution'])\n        dfs[category] = df\n    return dfs\n\ndef change_words(batch, transform=lambda x: x):\n    return [[transform(word) for word in entry] for entry in batch]","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:50.849377Z","iopub.execute_input":"2023-12-13T11:06:50.849736Z","iopub.status.idle":"2023-12-13T11:06:50.857930Z","shell.execute_reply.started":"2023-12-13T11:06:50.849711Z","shell.execute_reply":"2023-12-13T11:06:50.857101Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"data_sim = pd.read_csv(datapath('wordsim353.tsv'), sep='\\t', skiprows=2, names=[\"Word1\", \"Word2\", \"Human\"])\ndata_sim[\"Human\"] = round(data_sim[\"Human\"] / 10, 3)\ndata_quest = load_question_words(datapath('questions-words.txt'))\n\nprint(\"Word-Similarity Data\")\nprint(data_sim.size)\nprint(\"#############################################\")\nprint(\"Question-Words Data\")\nfor category, dataset in data_quest.items():\n    print(f\"{category:<25} \\t Size: {dataset.size}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:50.858970Z","iopub.execute_input":"2023-12-13T11:06:50.859224Z","iopub.status.idle":"2023-12-13T11:06:50.930222Z","shell.execute_reply.started":"2023-12-13T11:06:50.859201Z","shell.execute_reply":"2023-12-13T11:06:50.929316Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Word-Similarity Data\n1059\n#############################################\nQuestion-Words Data\ncapital-common-countries  \t Size: 2024\ncapital-world             \t Size: 18096\ncurrency                  \t Size: 3464\ncity-in-state             \t Size: 9868\nfamily                    \t Size: 2024\ngram1-adjective-to-adverb \t Size: 3968\ngram2-opposite            \t Size: 3248\ngram3-comparative         \t Size: 5328\ngram4-superlative         \t Size: 4488\ngram5-present-participle  \t Size: 4224\ngram6-nationality-adjective \t Size: 6396\ngram7-past-tense          \t Size: 6240\ngram8-plural              \t Size: 5328\ngram9-plural-verbs        \t Size: 3480\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Word similarity","metadata":{}},{"cell_type":"code","source":"def word_sim_function(emb, tok, x, dist=\"cosine\"):\n    result = torch.squeeze(1 - calc_distance(emb, x[\"Word1\"], x[\"Word2\"], tok=tok, dist=dist))\n    result = torch.round(result, decimals=3)\n    return result.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:50.931323Z","iopub.execute_input":"2023-12-13T11:06:50.932246Z","iopub.status.idle":"2023-12-13T11:06:50.937872Z","shell.execute_reply.started":"2023-12-13T11:06:50.932210Z","shell.execute_reply":"2023-12-13T11:06:50.936980Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Change tokens to embed\ndata_sim[\"Word1\"] = data_sim[\"Word1\"].apply(addspace)\ndata_sim[\"Word2\"] = data_sim[\"Word2\"].apply(addspace)\n# Calculate similarities\ndata_sim[\"Phi-1.5\"] = data_sim[[\"Word1\", \"Word2\"]].apply(lambda x: word_sim_function(phi_emb, tokenizer_phi, x), axis=1).astype(float)\ndata_sim[\"GPT-2\"] = data_sim[[\"Word1\", \"Word2\"]].apply(lambda x: word_sim_function(gpt_emb, tokenizer_gpt, x), axis=1).astype(float)\n# Generate absolute errors of data\ndata_sim[\"dPhi\"] = (data_sim[\"Human\"] - data_sim[\"Phi-1.5\"]).abs()\ndata_sim[\"dGPT\"] = (data_sim[\"Human\"] - data_sim[\"GPT-2\"]).abs()\n# Perform z-score normalization\ndata_sim[[\"zHuman\", \"zPhi-1.5\", \"zGPT-2\"]] = (data_sim[[\"Human\", \"Phi-1.5\", \"GPT-2\"]] - data_sim[[\"Human\", \"Phi-1.5\", \"GPT-2\"]].mean()) / data_sim[[\"Human\", \"Phi-1.5\", \"GPT-2\"]].std()\n# Generate absolute errors of normalized data\ndata_sim[\"dzPhi\"] = (data_sim[\"zHuman\"] - data_sim[\"zPhi-1.5\"]).abs()\ndata_sim[\"dzGPT\"] = (data_sim[\"zHuman\"] - data_sim[\"zGPT-2\"]).abs()","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:50.938981Z","iopub.execute_input":"2023-12-13T11:06:50.939229Z","iopub.status.idle":"2023-12-13T11:06:51.681109Z","shell.execute_reply.started":"2023-12-13T11:06:50.939207Z","shell.execute_reply":"2023-12-13T11:06:51.680365Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print(f\"{'MAE Phi-1.5':<22} : {data_sim['dPhi'].mean():.3}\")\nprint(f\"{'MAE GPT-2':<22} : {data_sim['dGPT'].mean():.3}\")\nprint(f\"{'MAE Phi-1.5 Normalized':<22} : {data_sim['dzPhi'].mean():.3}\")\nprint(f\"{'MAE GPT-2 Normalized':<22} : {data_sim['dzGPT'].mean():.3}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:51.682125Z","iopub.execute_input":"2023-12-13T11:06:51.682402Z","iopub.status.idle":"2023-12-13T11:06:51.689023Z","shell.execute_reply.started":"2023-12-13T11:06:51.682377Z","shell.execute_reply":"2023-12-13T11:06:51.687674Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"MAE Phi-1.5            : 0.485\nMAE GPT-2              : 0.244\nMAE Phi-1.5 Normalized : 0.723\nMAE GPT-2 Normalized   : 0.679\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Question Words","metadata":{}},{"cell_type":"code","source":"test_questions_phi = [\n    (category, batch_emb_arithmetic(phi_emb, tokenizer_phi, change_words(dataset.values.tolist(), addspace), k=10, out=False)) \n    for category, dataset in tqdm(data_quest.items())\n]\n\ntest_questions_gpt = [\n    (category, batch_emb_arithmetic(gpt_emb, tokenizer_gpt,change_words(dataset.values.tolist(), addspace), k=10, out=False)) \n    for category, dataset in tqdm(data_quest.items())\n]\n\ntest_question_sol = [[addall(entry) for entry in dataset.iloc[:, -1].to_list()] for dataset in data_quest.values()]","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:06:51.690245Z","iopub.execute_input":"2023-12-13T11:06:51.690586Z","iopub.status.idle":"2023-12-13T11:12:35.736629Z","shell.execute_reply.started":"2023-12-13T11:06:51.690560Z","shell.execute_reply":"2023-12-13T11:12:35.735711Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a32973fae7604b09a44096c8012a20ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad89ff303cac408396aa47ac0d33ad09"}},"metadata":{}}]},{"cell_type":"code","source":"for qp, qg, sol in zip(test_questions_phi, test_questions_gpt, test_question_sol):\n    name = qp[0]\n    print(\"---------------------------\")\n    print(name)\n    print(f\"Phi-1.5: {evaluate_batch(qp[1], sol, out=False):.2f}\")\n    print(f\"GPT-2: {evaluate_batch(qg[1], sol, out=False):.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:23:26.922853Z","iopub.execute_input":"2023-12-13T11:23:26.923768Z","iopub.status.idle":"2023-12-13T11:23:27.110102Z","shell.execute_reply.started":"2023-12-13T11:23:26.923735Z","shell.execute_reply":"2023-12-13T11:23:27.109145Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"---------------------------\ncapital-common-countries\nPhi-1.5: 0.46\nGPT-2: 0.73\n---------------------------\ncapital-world\nPhi-1.5: 0.12\nGPT-2: 0.22\n---------------------------\ncurrency\nPhi-1.5: 0.04\nGPT-2: 0.07\n---------------------------\ncity-in-state\nPhi-1.5: 0.16\nGPT-2: 0.32\n---------------------------\nfamily\nPhi-1.5: 0.58\nGPT-2: 0.66\n---------------------------\ngram1-adjective-to-adverb\nPhi-1.5: 0.47\nGPT-2: 0.49\n---------------------------\ngram2-opposite\nPhi-1.5: 0.48\nGPT-2: 0.43\n---------------------------\ngram3-comparative\nPhi-1.5: 0.75\nGPT-2: 0.90\n---------------------------\ngram4-superlative\nPhi-1.5: 0.59\nGPT-2: 0.77\n---------------------------\ngram5-present-participle\nPhi-1.5: 0.80\nGPT-2: 0.85\n---------------------------\ngram6-nationality-adjective\nPhi-1.5: 0.68\nGPT-2: 0.88\n---------------------------\ngram7-past-tense\nPhi-1.5: 0.68\nGPT-2: 0.82\n---------------------------\ngram8-plural\nPhi-1.5: 0.70\nGPT-2: 0.79\n---------------------------\ngram9-plural-verbs\nPhi-1.5: 0.76\nGPT-2: 0.84\n","output_type":"stream"}]}]}