{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install einops","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-09T19:53:51.263288Z","iopub.execute_input":"2023-12-09T19:53:51.264056Z","iopub.status.idle":"2023-12-09T19:54:03.293655Z","shell.execute_reply.started":"2023-12-09T19:53:51.264025Z","shell.execute_reply":"2023-12-09T19:54:03.292698Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting einops\n  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\nDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport torch\nimport copy\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:54:03.295753Z","iopub.execute_input":"2023-12-09T19:54:03.296170Z","iopub.status.idle":"2023-12-09T19:54:08.892694Z","shell.execute_reply.started":"2023-12-09T19:54:03.296131Z","shell.execute_reply":"2023-12-09T19:54:08.891235Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Import Models","metadata":{}},{"cell_type":"code","source":"device = \"cpu\"\ntorch.set_default_device(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:54:08.894307Z","iopub.execute_input":"2023-12-09T19:54:08.894759Z","iopub.status.idle":"2023-12-09T19:54:08.901679Z","shell.execute_reply.started":"2023-12-09T19:54:08.894731Z","shell.execute_reply":"2023-12-09T19:54:08.900565Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"phi = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\ntokenizer_phi = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\nconfig_phi = AutoConfig.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\n\nphi = phi.eval()\nphi.zero_grad()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:54:08.903948Z","iopub.execute_input":"2023-12-09T19:54:08.904784Z","iopub.status.idle":"2023-12-09T19:54:36.707628Z","shell.execute_reply.started":"2023-12-09T19:54:08.904754Z","shell.execute_reply":"2023-12-09T19:54:36.706543Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e06bb93cc78458f847a307fd02d5b5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi.py:   0%|          | 0.00/2.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23ee8bcedc014b83a6899c1271342ce7"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-1_5:\n- configuration_phi.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi.py:   0%|          | 0.00/33.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca22eb45da29400eb33f5fda10fca3e6"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-1_5:\n- modeling_phi.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.84G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b315fb959fb4fe7abe4d67077c7381b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dd1489115cb4aeb8206e58ab6f12dc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3ab4bc07dff428097b15039a3b70bf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61516de021814210b28c5c8fac8e52a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d18459a20a09447c97a10ba9f2ab8ee1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6472eb4a02f24907a29921ef67b34445"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0df36cf7298a4b85bfeae383ed9b077e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25993bab25c34d5d915d5f66c30894c9"}},"metadata":{}}]},{"cell_type":"code","source":"gpt = AutoModelForCausalLM.from_pretrained(\"gpt2\")\ntokenizer_gpt = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\nconfig_gpt = AutoConfig.from_pretrained(\"gpt2\", trust_remote_code=True)\n\ngpt.eval()\ngpt.zero_grad()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:54:36.709025Z","iopub.execute_input":"2023-12-09T19:54:36.709569Z","iopub.status.idle":"2023-12-09T19:54:42.019805Z","shell.execute_reply.started":"2023-12-09T19:54:36.709535Z","shell.execute_reply":"2023-12-09T19:54:42.018133Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a876c6798f44cd09b8c8cc687355cbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb5875fb017f4d9aa7d3e4e42bdf6d99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ba7448c6ee84c0cb35c12ee6b2ab5ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d82f2c7907a4b498fcb6ba1a6fd16c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"367cf3de6d7e4d4a862d1d7b29df9839"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d2c07bb6afa464295f387e7cf82fbb8"}},"metadata":{}}]},{"cell_type":"code","source":"phi_emb = phi.get_input_embeddings()\ngpt_emb = gpt.get_input_embeddings()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:54:42.021518Z","iopub.execute_input":"2023-12-09T19:54:42.021869Z","iopub.status.idle":"2023-12-09T19:54:42.028109Z","shell.execute_reply.started":"2023-12-09T19:54:42.021840Z","shell.execute_reply":"2023-12-09T19:54:42.026801Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Define Helper Functions","metadata":{}},{"cell_type":"code","source":"def multiencode(tok, words, return_tensors=\"pt\"):\n    if (isinstance(words, list) or isinstance(words, tuple)) and not isinstance(words, str):\n        return torch.cat([tok.encode(word, return_tensors=\"pt\") for word in words], dim=-1)\n    else:\n        return tok.encode(words, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:54:42.029406Z","iopub.execute_input":"2023-12-09T19:54:42.029670Z","iopub.status.idle":"2023-12-09T19:54:42.040549Z","shell.execute_reply.started":"2023-12-09T19:54:42.029647Z","shell.execute_reply":"2023-12-09T19:54:42.039323Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_closest_emb(emb, word, k=1, decode=True, tok=None, avg=False):\n    # If input is a string tokenize it\n    if (isinstance(word, str) or isinstance(word[0], str)) and tok is not None:\n        word = emb(multiencode(tok, word))\n    # Calculate average if flag and needed\n    if word.shape[1] != 1 and avg:\n        word = torch.unsqueeze(torch.mean(word, dim=1), dim=1)\n    # Compute normalized distances\n    distances = torch.norm(emb.weight.data - word, dim=2)\n    # Compute top k smalles indices\n    topk = torch.squeeze(torch.topk(distances, k=k, largest=False).indices)\n    # If one element, unsqueeze it\n    if k == 1:\n        topk = torch.unsqueeze(topk, dim=0)\n    # Decode closest k\n    if decode and tok is not None:\n        topk = [tok.decode(c) for c in topk.tolist()]\n    return topk\n\ndef emb_arithmetic(emb, tok, words, k=1, avg=False, norm=False):\n    # Convert all words into tokens\n    words_emb = [multiencode(tok, word) for word in words]\n    # Convert all tokens into embeddings\n    for i, word in enumerate(words_emb):\n        if word.shape[1] == 1:\n            words_emb[i] = emb(word)\n        elif avg:\n            words_emb[i] = torch.unsqueeze(torch.mean(emb(word), dim=1), dim=1)\n        else:\n            raise Exception(f\"{words[i]} is not a single token: {word}\")\n    # Compute embeddings\n    w1 = words_emb[0]\n    w2 = words_emb[1]\n    w3 = words_emb[2]\n    # Do embedding arithmetic\n    if norm:\n        w = torch.nn.functional.normalize(w1 - w2 + w3, dim=0)\n    else:\n        w = w1 - w2 + w3\n    # Get closest k\n    closest = get_closest_emb(emb, w, k=k, decode=True, tok=tok)\n    return (w, closest)\n\ndef print_results(res):\n     for i, r in enumerate(res):\n        print(f\"{i+1}) {r}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:54:42.042291Z","iopub.execute_input":"2023-12-09T19:54:42.042741Z","iopub.status.idle":"2023-12-09T19:54:42.057108Z","shell.execute_reply.started":"2023-12-09T19:54:42.042711Z","shell.execute_reply":"2023-12-09T19:54:42.055027Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def batch_emb_arithmetic(emb, tok, queries, k=5, avg=False, norm=False, out=True):\n    ret = []\n    for q in queries:\n        if out:\n            print(\"##########################\")\n            # Print title\n            title_q = q\n            if not isinstance(q[0], str):\n                title_q = [qq[0] for qq in q]\n            print(f\"{title_q[0]} - {title_q[1]} + {title_q[2]} =\")\n        # Compute and print results\n        res = emb_arithmetic(emb, tok, q, k=k, avg=avg, norm=norm)\n        if out:\n            print_results(res[1])\n        ret.append(res)\n    return ret\n\ndef evaluate_batch(results, solutions, out=True):\n    \n    def get_rank(r, s, out=0):\n        try:\n            return r.index(s)\n        except ValueError:\n            return out\n    \n    k = len(results[0][1])\n    ev = []\n    for res, sol in zip(list(map(lambda x: x[1], results)), solutions):\n        # Get rank of each solution for each result outputs\n        ranks = [get_rank(res, s, out=k) for s in sol]\n        # Append best rank to final evaluation list\n        ev.append(min(ranks))\n    # Return score\n    score = 1 - ( sum(ev) / (k * len(solutions)) )\n    if out:\n        print(f\"{ev} -> {score}\")\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:54:42.058654Z","iopub.execute_input":"2023-12-09T19:54:42.059104Z","iopub.status.idle":"2023-12-09T19:54:42.075610Z","shell.execute_reply.started":"2023-12-09T19:54:42.059070Z","shell.execute_reply":"2023-12-09T19:54:42.074045Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Define Test Cases","metadata":{}},{"cell_type":"markdown","source":"### Capital Arithmetic","metadata":{}},{"cell_type":"code","source":"capital_arithmetic = [\n    [\"Rome Rome\", \"Italy Italy\", \"France France\"],\n    [\"Rome Rome\", \"Italy Italy\", \"Australia Australia\"],\n    [\"Paris Paris\", \"France France\", \"Italy Italy\"],\n    [\"Paris Paris\", \"France France\", \"Australia Australia\"],\n    [\"Canberra Canberra\", \"Australia Australia\", \"Italy Italy\"],\n    [\"Canberra Canberra\", \"Australia Australia\", \"France France\"],\n]\ncapital_single = [\n    [\" Rome\", \" Italy\", \" France\"],\n    [\" Rome\", \" Italy\", \" Australia\"],\n    [\" Paris\", \" France\", \" Italy\"],\n    [\" Paris\", \" France\", \" Australia\"],\n    [\" Canberra\", \" Australia\", \" Italy\"],\n    [\" Canberra\", \" Australia\", \" France\"],\n]\ncapital_arithmetic_lowercase = [\n    [\"rome rome\", \"italy italy\", \"france france\"],\n    [\"rome rome\", \"italy italy\", \"australia australia\"],\n    [\"paris paris\", \"france france\", \"italy italy\"],\n    [\"paris paris\", \"france france\", \"australia australia\"],\n    [\"canberra canberra\", \"australia australia\", \"italy italy\"],\n    [\"canberra canberra\", \"australia australia\", \"france france\"],\n]\ncapital_sol = [\n    [\"Paris\", \" Paris\", \"paris\", \" paris\"],\n    [\"Canberra\", \" Canberra\", \"canberra\", \" canberra\"],\n    [\"Rome\", \" Rome\", \"rome\", \" rome\"],\n    [\"Canberra\", \" Canberra\", \"canberra\", \" canberra\"],\n    [\"Rome\", \" Rome\", \"rome\", \" rome\"],\n    [\"Paris\", \" Paris\", \"paris\", \" paris\"],\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:54:42.080537Z","iopub.execute_input":"2023-12-09T19:54:42.082022Z","iopub.status.idle":"2023-12-09T19:54:42.093738Z","shell.execute_reply.started":"2023-12-09T19:54:42.081855Z","shell.execute_reply":"2023-12-09T19:54:42.091931Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Sex Arithmetic","metadata":{}},{"cell_type":"code","source":"sex_arithmetic = [\n    [\"King King\", \"Man Man\", \"Woman Woman\"],\n    [\"Queen Queen\", \"Woman Woman\", \"Man Man\"],\n    [\"Prince Prince\", \"Man Man\", \"Woman Woman\"],\n    [\"Princess Princess\", \"Woman Woman\", \"Man Man\"],\n    [\"Priest Priest\", \"Man Man\", \"Woman Woman\"],\n    [\"Nun Nun\", \"Woman Woman\", \"Man Man\"],\n]\nsex_arithmetic_lowercase_single = [\n    [\" king\", \" man\", \" woman\"],\n    [\" queen\", \" woman\", \" man\"],\n    [\" prince\", \" man\", \" woman\"],\n    [\" princess\", \" woman\", \" man\"],\n    [\" priest\", \" man\", \" woman\"],\n    [\" nun\", \" woman\", \" man\"],\n]\nsex_sol = [\n    [\"Queen\", \" Queen\", \"queen\", \" queen\"],\n    [\"King\", \" King\", \"king\", \" king\"],\n    [\"Princess\", \" Princess\", \"princess\", \" princess\"],\n    [\"Prince\", \" Prince\", \"prince\", \" prince\"],\n    [\"Nun\", \" Nun\", \"nun\", \" nun\"],\n    [\"Priest\", \" Priest\", \"priest\", \" priest\"],\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:54:42.095138Z","iopub.execute_input":"2023-12-09T19:54:42.095946Z","iopub.status.idle":"2023-12-09T19:54:42.109838Z","shell.execute_reply.started":"2023-12-09T19:54:42.095909Z","shell.execute_reply":"2023-12-09T19:54:42.108538Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Calculate and Display Test Results","metadata":{}},{"cell_type":"code","source":"test_capital = [\n    [\"Phi-1.5\", batch_emb_arithmetic(phi_emb, tokenizer_phi, capital_arithmetic, k=100, avg=True, norm=False, out=False)],\n    [\"Phi-1.5 Normalized\", batch_emb_arithmetic(phi_emb, tokenizer_phi, capital_arithmetic, k=100, avg=True, norm=True, out=False)],\n    [\"Phi-1.5 Lowercase\", batch_emb_arithmetic(phi_emb, tokenizer_phi, capital_arithmetic_lowercase, k=100, avg=True, norm=False, out=False)],\n    [\"Phi-1.5 Normalized Lowercase\", batch_emb_arithmetic(phi_emb, tokenizer_phi, capital_arithmetic_lowercase, k=100, avg=True, norm=True, out=False)],\n    [\"Phi-1.5 Single\", batch_emb_arithmetic(phi_emb, tokenizer_phi, capital_single, k=100, avg=True, norm=False, out=False)],\n    [\"Phi-1.5 Normalized Single\", batch_emb_arithmetic(phi_emb, tokenizer_phi, capital_single, k=100, avg=True, norm=True, out=False)],\n    [\"GPT-2\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, capital_arithmetic, k=100, avg=True, norm=False, out=False)],\n    [\"GPT-2 Normalized\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, capital_arithmetic, k=100, avg=True, norm=True, out=False)],\n    [\"GPT-2 Lowercase\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, capital_arithmetic_lowercase, k=100, avg=True, norm=False, out=False)],\n    [\"GPT-2 Normalized Lowercase\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, capital_arithmetic_lowercase, k=100, avg=True, norm=True, out=False)],\n    [\"GPT-2 Single\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, capital_single, k=100, avg=True, norm=False, out=False)],\n    [\"GPT-2 Normalized Single\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, capital_single, k=100, avg=True, norm=True, out=False)],\n]\ntest_sex = [\n    [\"Phi-1.5\", batch_emb_arithmetic(phi_emb, tokenizer_phi, sex_arithmetic, k=100, avg=True, norm=False, out=False)],\n    [\"Phi-1.5 Normalized\", batch_emb_arithmetic(phi_emb, tokenizer_phi, sex_arithmetic, k=100, avg=True, norm=True, out=False)],\n    [\"Phi-1.5 Lowercase Single\", batch_emb_arithmetic(phi_emb, tokenizer_phi, sex_arithmetic_lowercase_single, k=100, avg=True, norm=False, out=False)],\n    [\"Phi-1.5 Normalized Lowercase Single\", batch_emb_arithmetic(phi_emb, tokenizer_phi, sex_arithmetic_lowercase_single, k=100, avg=True, norm=True, out=False)],\n    [\"GPT-2\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, sex_arithmetic, k=100, avg=True, norm=False, out=False)],\n    [\"GPT-2 Normalized\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, sex_arithmetic, k=100, avg=True, norm=True, out=False)],\n    [\"GPT-2 Lowercase Single\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, sex_arithmetic_lowercase_single, k=100, avg=True, norm=False, out=False)],\n    [\"GPT-2 Normalized Lowercase Single\", batch_emb_arithmetic(gpt_emb, tokenizer_gpt, sex_arithmetic_lowercase_single, k=100, avg=True, norm=True, out=False)],\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:54:42.113172Z","iopub.execute_input":"2023-12-09T19:54:42.114021Z","iopub.status.idle":"2023-12-09T19:55:07.851561Z","shell.execute_reply.started":"2023-12-09T19:54:42.113987Z","shell.execute_reply":"2023-12-09T19:55:07.849913Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(\"Capital rankings\")\nfor name, result in test_capital:\n    print(\"---------------------------\")\n    print(name)\n    evaluate_batch(result, capital_sol)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:55:07.853251Z","iopub.execute_input":"2023-12-09T19:55:07.853897Z","iopub.status.idle":"2023-12-09T19:55:07.860574Z","shell.execute_reply.started":"2023-12-09T19:55:07.853871Z","shell.execute_reply":"2023-12-09T19:55:07.859830Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Capital rankings\n---------------------------\nPhi-1.5\n[100, 100, 100, 100, 100, 100] -> 0.0\n---------------------------\nPhi-1.5 Normalized\n[14, 100, 5, 21, 9, 6] -> 0.7416666666666667\n---------------------------\nPhi-1.5 Lowercase\n[100, 100, 100, 100, 100, 100] -> 0.0\n---------------------------\nPhi-1.5 Normalized Lowercase\n[100, 100, 100, 100, 100, 100] -> 0.0\n---------------------------\nPhi-1.5 Single\n[100, 100, 100, 100, 100, 100] -> 0.0\n---------------------------\nPhi-1.5 Normalized Single\n[3, 25, 13, 24, 6, 4] -> 0.875\n---------------------------\nGPT-2\n[2, 67, 7, 11, 64, 4] -> 0.7416666666666667\n---------------------------\nGPT-2 Normalized\n[4, 3, 15, 1, 12, 4] -> 0.935\n---------------------------\nGPT-2 Lowercase\n[100, 100, 100, 100, 100, 100] -> 0.0\n---------------------------\nGPT-2 Normalized Lowercase\n[100, 100, 100, 100, 100, 100] -> 0.0\n---------------------------\nGPT-2 Single\n[2, 5, 3, 12, 4, 4] -> 0.95\n---------------------------\nGPT-2 Normalized Single\n[3, 2, 11, 3, 9, 2] -> 0.95\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Sex rankings\")\nfor name, result in test_sex:\n    print(\"---------------------------\")\n    print(name)\n    evaluate_batch(result, sex_sol)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:55:07.861583Z","iopub.execute_input":"2023-12-09T19:55:07.861858Z","iopub.status.idle":"2023-12-09T19:55:07.877226Z","shell.execute_reply.started":"2023-12-09T19:55:07.861810Z","shell.execute_reply":"2023-12-09T19:55:07.875569Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Sex rankings\n---------------------------\nPhi-1.5\n[100, 100, 100, 100, 100, 100] -> 0.0\n---------------------------\nPhi-1.5 Normalized\n[6, 7, 5, 24, 100, 100] -> 0.5966666666666667\n---------------------------\nPhi-1.5 Lowercase Single\n[100, 100, 100, 100, 100, 100] -> 0.0\n---------------------------\nPhi-1.5 Normalized Lowercase Single\n[4, 3, 2, 4, 16, 7] -> 0.94\n---------------------------\nGPT-2\n[3, 2, 3, 4, 100, 100] -> 0.6466666666666667\n---------------------------\nGPT-2 Normalized\n[2, 2, 5, 3, 29, 100] -> 0.765\n---------------------------\nGPT-2 Lowercase Single\n[1, 1, 1, 1, 7, 3] -> 0.9766666666666667\n---------------------------\nGPT-2 Normalized Lowercase Single\n[0, 2, 1, 1, 3, 8] -> 0.975\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Visualizations ","metadata":{}},{"cell_type":"code","source":"_ = batch_emb_arithmetic(gpt_emb, tokenizer_gpt, capital_arithmetic, k=10, avg=True, norm=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:55:07.879333Z","iopub.execute_input":"2023-12-09T19:55:07.879876Z","iopub.status.idle":"2023-12-09T19:55:08.232050Z","shell.execute_reply.started":"2023-12-09T19:55:07.879809Z","shell.execute_reply":"2023-12-09T19:55:08.230412Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"##########################\nRome Rome - Italy Italy + France France =\n1) France\n2) ome\n3)  France\n4) French\n5) Paris\n6)  Paris\n7)  French\n8)  Frenchman\n9) ô\n10)  Lyon\n##########################\nRome Rome - Italy Italy + Australia Australia =\n1) Australia\n2)  Australia\n3)  Sydney\n4)  Canberra\n5) Australian\n6)  Australian\n7)  Australians\n8)  Perth\n9)  Aboriginal\n10)  Melbourne\n##########################\nParis Paris - France France + Italy Italy =\n1) Paris\n2) Italy\n3)  Paris\n4)  Milan\n5) Italian\n6)  Italy\n7)  Lisbon\n8)  Budapest\n9)  Italians\n10)  Venice\n##########################\nParis Paris - France France + Australia Australia =\n1) Australia\n2)  Canberra\n3)  Australians\n4) Austral\n5)  Australia\n6) Paris\n7)  Sydney\n8) Australian\n9)  Melbourne\n10)  Australian\n##########################\nCanberra Canberra - Australia Australia + Italy Italy =\n1) Italy\n2)  Italy\n3)  Italians\n4) berra\n5) Italian\n6)  Sicily\n7)  Naples\n8)  Serie\n9)  Italian\n10)  Juventus\n##########################\nCanberra Canberra - Australia Australia + France France =\n1) France\n2) French\n3) berra\n4)  France\n5) Paris\n6)  François\n7)  Frenchman\n8)  Francois\n9)  Hollande\n10)  Marse\n","output_type":"stream"}]},{"cell_type":"code","source":"_ = batch_emb_arithmetic(phi_emb, tokenizer_phi, capital_arithmetic, k=10, avg=True, norm=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:55:08.234176Z","iopub.execute_input":"2023-12-09T19:55:08.234543Z","iopub.status.idle":"2023-12-09T19:55:09.105090Z","shell.execute_reply.started":"2023-12-09T19:55:08.234513Z","shell.execute_reply":"2023-12-09T19:55:09.103135Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"##########################\nRome Rome - Italy Italy + France France =\n1)  France\n2) R\n3) France\n4) ome\n5)  Rome\n6)  R\n7)  French\n8) M\n9) r\n10) F\n##########################\nRome Rome - Italy Italy + Australia Australia =\n1)  Australia\n2) Australia\n3) R\n4)  Australian\n5) ome\n6)  R\n7)  Australians\n8)  Rome\n9) r\n10) S\n##########################\nParis Paris - France France + Italy Italy =\n1)  Paris\n2)  Italy\n3) Paris\n4) Italy\n5)  Italian\n6)  Rome\n7) Italian\n8)  Milan\n9)  Lisbon\n10)  Tokyo\n##########################\nParis Paris - France France + Australia Australia =\n1)  Australia\n2)  Paris\n3) Australia\n4) Paris\n5)  Australian\n6)  Sydney\n7)  Australians\n8)  Melbourne\n9) Australian\n10)  Canada\n##########################\nCanberra Canberra - Australia Australia + Italy Italy =\n1)  Italy\n2) Can\n3) Italy\n4)  Italian\n5) Italian\n6)  Can\n7)  Canberra\n8)  Italians\n9) can\n10)  Rome\n##########################\nCanberra Canberra - Australia Australia + France France =\n1)  France\n2) France\n3) Can\n4)  French\n5)  Can\n6)  Canberra\n7)  Paris\n8) French\n9)  Italy\n10) Paris\n","output_type":"stream"}]},{"cell_type":"code","source":"_ = batch_emb_arithmetic(gpt_emb, tokenizer_gpt, sex_arithmetic_lowercase_single, k=10, avg=True, norm=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:55:09.106657Z","iopub.execute_input":"2023-12-09T19:55:09.107004Z","iopub.status.idle":"2023-12-09T19:55:09.447314Z","shell.execute_reply.started":"2023-12-09T19:55:09.106976Z","shell.execute_reply":"2023-12-09T19:55:09.446371Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"##########################\n king -  man +  woman =\n1)  queen\n2)  king\n3) Queen\n4)  kings\n5)  Queen\n6)  princess\n7)  queens\n8)  pope\n9)  King\n10) King\n##########################\n queen -  woman +  man =\n1)  queen\n2)  queens\n3)  king\n4)  kings\n5)  Queen\n6) Queen\n7)  emperor\n8)  rook\n9) King\n10)  monarch\n##########################\n prince -  man +  woman =\n1)  prince\n2)  princess\n3)  princes\n4) Prince\n5)  Princess\n6)  queen\n7)  Prince\n8) Prin\n9)  Duchess\n10)  heroine\n##########################\n princess -  woman +  man =\n1)  princess\n2)  prince\n3)  princes\n4)  Princess\n5) Prin\n6)  Prince\n7) Prince\n8)  king\n9)  knight\n10)  Cinderella\n##########################\n priest -  man +  woman =\n1)  priest\n2)  priests\n3)  Priest\n4)  nun\n5)  clergy\n6)  prostitute\n7)  nuns\n8)  bishop\n9) Catholic\n10)  priesthood\n##########################\n nun -  woman +  man =\n1)  nun\n2)  nuns\n3)  monk\n4)  convent\n5)  pope\n6)  monks\n7)  Jesuit\n8)  monastery\n9)  priest\n10)  Archbishop\n","output_type":"stream"}]},{"cell_type":"code","source":"res = get_closest_emb(phi_emb, \" nun\", k=10, tok=tokenizer_phi, avg=True)\nprint_results(res)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:55:09.448549Z","iopub.execute_input":"2023-12-09T19:55:09.448787Z","iopub.status.idle":"2023-12-09T19:55:09.600232Z","shell.execute_reply.started":"2023-12-09T19:55:09.448764Z","shell.execute_reply":"2023-12-09T19:55:09.599242Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"1)  nun\n2)  Skydragon\n3) wcsstore\n4)  \"$:/\n5) �\n6)  guiName\n7)  裏�\n8)  externalTo\n9) ertodd\n10)  Smartstocks\n","output_type":"stream"}]},{"cell_type":"code","source":"res = get_closest_emb(gpt_emb, \" nun\", k=10, tok=tokenizer_gpt, avg=True)\nprint_results(res)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T19:55:09.601407Z","iopub.execute_input":"2023-12-09T19:55:09.601743Z","iopub.status.idle":"2023-12-09T19:55:09.656196Z","shell.execute_reply.started":"2023-12-09T19:55:09.601707Z","shell.execute_reply":"2023-12-09T19:55:09.654925Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"1)  nun\n2)  nuns\n3)  convent\n4)  priest\n5)  monk\n6)  monastery\n7) �\n8) \u0002\n9) \u0010\n10) \u0011\n","output_type":"stream"}]}]}