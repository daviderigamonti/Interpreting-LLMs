# Paper Organization

[Google Sheets Link](https://docs.google.com/spreadsheets/d/13AIEp3gyqf4AO1MgAZmUANgor4021n0Bx-NNuwTvYqM/edit#gid=0)

# Papers

## [Exposing Attention Glitches with Flip-Flop Language Modeling](https://arxiv.org/abs/2306.00946)
- [Local Copy](PDFs/dola_decoding_by_contrasting_layers_improves_factuality_in_large_language_models.pdf)
- [Annotated Copy]()

## [DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models](https://arxiv.org/abs/2309.03883)
- [Local Copy](PDFs/dola_decoding_by_contrasting_layers_improves_factuality_in_large_language_models.pdf)
- [Annotated Copy]()
- [Github](https://github.com/voidism/DoLa)

# Previous Meeting Ideas

## 28/11/23 w/ Mark, Nicolò, Vincenzo

## 30/11/23 w/ Nicolò, Vincenzo

- Restating new research topics
    - How does the memory of a model work/change when learning new facts?
    - Where is the memory of a model stored, and how is it represented?

- Organize previous papers on a spreadsheet

- New papers
    - [Exposing Attention Glitches with Flip-Flop Language Modeling](https://arxiv.org/abs/2306.00946)
    - [DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models](https://arxiv.org/abs/2309.03883)
        - https://github.com/voidism/DoLa

- Verify classic spatial embedding properties on newer transformer models